{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN with Functional.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX3v72PlE5FD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, LeakyReLU, Reshape, Conv2DTranspose, Conv2D, Dropout, Flatten\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import os\n",
        "!pip install scikit-tda\n",
        "import sys\n",
        "\n",
        "# if not sys.warnoptions:\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB-PpMRIFRIC",
        "colab_type": "code",
        "outputId": "9ef29569-b490-4b98-a79a-ddf7a026ba54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print (tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03RPzJQpW32Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Build_Generator_Model():\n",
        "    '''\n",
        "    Generator model:\n",
        "    Input: random seed\n",
        "    Upsamples to produce an image \n",
        "    Output: 28x28x1 image\n",
        "    '''\n",
        "    model = Sequential()\n",
        "    model.add(Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2swypq0aXNk-",
        "colab_type": "code",
        "outputId": "9a37ecd9-cd2f-4719-944d-0f7a92dc0d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "Generator = Build_Generator_Model()\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image_test = Generator(noise, training=False)\n",
        "print(generated_image_test.shape)\n",
        "plt.imshow(generated_image_test[0,:,:,0], cmap='gray')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f00ccec1a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdsJbgjWGBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Build_Discriminator_Model_Functional():\n",
        "  '''\n",
        "  CNN with persistence encoding concatenated \n",
        "  '''\n",
        "\n",
        "  img_input = keras.Input(shape=[28,28,1], name='image')\n",
        "  vector = keras.Input(shape=[2], name='persistence_vector')\n",
        "  x = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(img_input)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "  x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  y = layers.concatenate([x,vector])\n",
        "  out = layers.Dense(1)(y)\n",
        "  model = keras.Model(inputs = [img_input, vector], outputs=out)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYchXakzcciy",
        "colab_type": "code",
        "outputId": "3cea8c92-1ac6-465c-f723-3aa0c749011e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "generated_image_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 28, 28, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TBe6N0OXKi4",
        "colab_type": "code",
        "outputId": "d07ce7bb-62d8-4671-ae2e-9dcb66e150b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "Discriminator = Build_Discriminator_Model_Functional()\n",
        "Discriminator.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "image (InputLayer)              [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 14, 14, 64)   1664        image[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 14, 14, 64)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 14, 14, 64)   0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 7, 7, 128)    204928      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 7, 7, 128)    0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 128)    0           leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 6272)         0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "persistence_vector (InputLayer) [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 6274)         0           flatten[0][0]                    \n",
            "                                                                 persistence_vector[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            6275        concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 212,867\n",
            "Trainable params: 212,867\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BknPo0qPXSu0",
        "colab_type": "code",
        "outputId": "a4c15def-f7e2-49b0-a8b6-77cca7ca25dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "times = tf.constant([10,1,1,1], tf.int32) \n",
        "print(tf.tile(generated_image_test, times).shape)\n",
        "Decision_Test = Discriminator([generated_image_test, tf.zeros([1,2])])\n",
        "#{'persistence_vector': tf.zeros([10,28], dtype=tf.float32),'image': tf.tile(generated_image_test, times)})"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK0vj_hmefnn",
        "colab_type": "code",
        "outputId": "31c32bbb-e4a2-4fed-ed4c-729dcecdbfdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(Decision_Test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[-0.00139694]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khJKSdk4ehug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Generator_Optimizer = Adam(1e-4)\n",
        "Discriminator_Optimizer = Adam(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NohoRrbEk8Q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(Generator_Optimizer=Generator_Optimizer, Discriminator_Optimizer=Discriminator_Optimizer, Generator=Generator, Discriminator=Discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3dMs__ck_aV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68df0fbb-90fc-43dd-ad58-6c79cbe26da9"
      },
      "source": [
        "cross_entropy = BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def Generator_Loss(fake_output):\n",
        "    '''\n",
        "    Define loss function for Generator Model \n",
        "    Discriminator output for each image is compared to an array of 1's \n",
        "    '''\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "def Discriminator_Loss(real_output, fake_output):\n",
        "    '''\n",
        "    Defines loss function for Discriminator Model\n",
        "    1 is assigned to Real Images\n",
        "    0 is assigned to Fake Images\n",
        "    Output: Sum Total Loss\n",
        "    '''\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "from ripser import Rips\n",
        "rips = Rips()\n",
        "\n",
        "EPOCHS = 75\n",
        "NOISE_DIM = 100\n",
        "Num_Images_to_Generate = 10\n",
        "seed = tf.random.normal([Num_Images_to_Generate, NOISE_DIM])\n",
        "\n",
        "@tf.function\n",
        "def evaluate_generator():\n",
        "    noise = tf.random.normal([Batch_Size, NOISE_DIM])\n",
        "    # with tf.GradientTape(watch_accessed_variables=False) as gt:\n",
        "    G_Images = Generator(noise, training=False)\n",
        "    return G_Images, noise\n",
        "\n",
        "def create_persistence(images):\n",
        "  images = tf.squeeze(images).numpy()\n",
        "  batch_vectors=[]\n",
        "  for i in range(images.shape[0]):\n",
        "      img = images[i,:,:]\n",
        "      diagrams = rips.fit_transform(img, metric='manhattan')\n",
        "      app = [sum(x) for x in zip(*diagrams[1])]\n",
        "      if len(app)<2:\n",
        "        app = [0. , 0.]\n",
        "      batch_vectors.append(app)\n",
        "  batch_vector = tf.constant(batch_vectors)\n",
        "  return batch_vector\n",
        "\n",
        "\n",
        "def evaluate_discriminator(images,real_persistence, fake_persistence, noise):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        Generated_Images = Generator(noise, training=True)\n",
        "        real_output = Discriminator([images, real_persistence], training=True)\n",
        "        fake_output = Discriminator([Generated_Images, fake_persistence], training=True)\n",
        "        Gen_Loss = Generator_Loss(fake_output)\n",
        "        Disc_Loss = Discriminator_Loss(real_output, fake_output)\n",
        "\n",
        "    Generator_Grads = gen_tape.gradient(Gen_Loss, Generator.trainable_variables)\n",
        "    Discriminator_Grads = disc_tape.gradient(Disc_Loss, Discriminator.trainable_variables)\n",
        "    Generator_Optimizer.apply_gradients(zip(Generator_Grads, Generator.trainable_variables))\n",
        "    Discriminator_Optimizer.apply_gradients(zip(Discriminator_Grads, Discriminator.trainable_variables))\n",
        "\n",
        "\n",
        "def all_together(images):\n",
        "  Generated_Images, noise = evaluate_generator()\n",
        "  real_persistence = create_persistence(images)\n",
        "  fake_persistence = create_persistence(Generated_Images)\n",
        "  evaluate_discriminator(images, real_persistence, fake_persistence, noise)\n",
        "\n",
        "@tf.function\n",
        "def Train_Step(images, zeros):\n",
        "    noise = tf.random.normal([Batch_Size, NOISE_DIM])\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        Generated_Images = Generator(noise, training=True)\n",
        "        real_output = Discriminator([images, zeros], training=True)\n",
        "        fake_output = Discriminator([Generated_Images,zeros], training=True)\n",
        "        Gen_Loss = Generator_Loss(fake_output)\n",
        "        Disc_Loss = Discriminator_Loss(real_output, fake_output)\n",
        "\n",
        "    Generator_Grads = gen_tape.gradient(Gen_Loss, Generator.trainable_variables)\n",
        "    Discriminator_Grads = disc_tape.gradient(Disc_Loss, Discriminator.trainable_variables)\n",
        "    Generator_Optimizer.apply_gradients(zip(Generator_Grads, Generator.trainable_variables))\n",
        "    Discriminator_Optimizer.apply_gradients(zip(Discriminator_Grads, Discriminator.trainable_variables))\n",
        "\n",
        "\n",
        "def Generate_and_Save_Images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(predictions[i, :, : , 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def Train(Dataset, epochs):\n",
        "    '''\n",
        "    Train the DCGAN on a Dataset for a given number of epochs\n",
        "    ''' \n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for k, image_batch in enumerate(Dataset):\n",
        "            all_together(image_batch)\n",
        "            if k %70 ==0:\n",
        "              print('batch {} done'.format(k))\n",
        "        Generate_and_Save_Images(Generator, epoch + 1, seed)\n",
        "        if(epoch + 1) % 15 == 0:\n",
        "          checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "        print(f'Time for Epoch: {epoch + 1} is {time.time() - start}')\n",
        "    Generate_and_Save_Images(Generator, epochs, seed)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rips(maxdim=1, thresh=inf, coeff=2, do_cocycles=False, n_perm = None, verbose=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDcQYPmTlwoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load data - prepare training data and normalize images to -1, 1\n",
        "(train_images, train_labels), (temp_images, temp_labels) = mnist.load_data()\n",
        "Train_images = np.append(train_images, temp_images, axis=0)\n",
        "Train_labels = np.append(train_labels, temp_labels, axis=0)\n",
        "Train_images = Train_images.reshape(Train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "Train_images = (Train_images - 127.5) / 127.5\n",
        "Buffer_Size = 70000\n",
        "Batch_Size = 250\n",
        "Train_Data_Set = tf.data.Dataset.from_tensor_slices(Train_images).shuffle(Buffer_Size).batch(Batch_Size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIwuc5onl01K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train(Train_Data_Set, EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}